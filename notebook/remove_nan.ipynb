{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/torch18/lib/python3.8/site-packages/llvmlite/llvmpy/__init__.py:3: UserWarning: The module `llvmlite.llvmpy` is deprecated and will be removed in the future.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/torch18/lib/python3.8/site-packages/llvmlite/llvmpy/core.py:8: UserWarning: The module `llvmlite.llvmpy.core` is deprecated and will be removed in the future. Equivalent functionality is provided by `llvmlite.ir`.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/torch18/lib/python3.8/site-packages/llvmlite/llvmpy/passes.py:17: UserWarning: The module `llvmlite.llvmpy.passes` is deprecated and will be removed in the future. If you are using this code, it should be inlined into your own project.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/mediazen/speech2anim/')\n",
    "\n",
    "from utils import plot_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/root/mediazen/speech2anim/merged_essentials/audio_ggongggong.pt',\n",
       " '/root/mediazen/speech2anim/merged_essentials/shape_ggongggong.pt')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/root/mediazen/speech2anim/merged_essentials'\n",
    "essentials_dir = [d.path for d in os.scandir(data_dir)]\n",
    "audio_path, shape_path = essentials_dir\n",
    "audio_path, shape_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_pt = torch.load(audio_path)\n",
    "shape_pt = torch.load(shape_path)\n",
    "\n",
    "len(audio_pt), len(shape_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for idx, spec in enumerate(audio_pt[2]):\n",
    "    if torch.isnan(spec).sum() > 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_delete(tensor, remove_idx):\n",
    "    return torch.cat((tensor[:remove_idx], tensor[remove_idx+1:])).detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([598])\n",
      "torch.Size([597])\n",
      "torch.Size([598, 8376, 161])\n",
      "torch.Size([597, 8376, 161])\n",
      "torch.Size([598])\n",
      "torch.Size([597])\n"
     ]
    }
   ],
   "source": [
    "new_audio_pt = list(audio_pt)\n",
    "\n",
    "for i in [1, 2, 3]:\n",
    "    print(new_audio_pt[i].shape)\n",
    "    new_audio_pt[i] = tensor_delete(new_audio_pt[i], remove_idx)\n",
    "    print(new_audio_pt[i].shape)\n",
    "\n",
    "new_audio_pt = tuple(new_audio_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([598, 5028])\n",
      "torch.Size([597, 5028])\n",
      "torch.Size([598, 5028, 16])\n",
      "torch.Size([597, 5028, 16])\n",
      "torch.Size([598])\n",
      "torch.Size([597])\n"
     ]
    }
   ],
   "source": [
    "new_shape_pt = list(shape_pt)\n",
    "\n",
    "for i in [0, 3, 4]:\n",
    "    print(new_shape_pt[i].shape)\n",
    "    new_shape_pt[i] = tensor_delete(new_shape_pt[i], remove_idx)\n",
    "    print(new_shape_pt[i].shape)\n",
    "\n",
    "new_shape_pt = tuple(new_shape_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_audio_pt, '/root/mediazen/speech2anim/modified_essentials/audio_ggongggong.pt')\n",
    "torch.save(new_shape_pt, '/root/mediazen/speech2anim/modified_essentials/shape_ggongggong.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('torch18')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98f3181f4900a3173dff2251935f87d1f345563f3a07cb125f858d750ad52894"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
